

"""
File name:  MDM_CANONICAL_JSON_UNPACK.py
Author: Naushad Baig, Snowflake Solution Architect, Cognizant Technoloyg solutions 
Created: Oct,2024
Version: 1.0
Description: common framework to unpack the json nested attributes to tabular format 
"""
from snowflake.snowpark.functions import col
from snowflake.snowpark.files import SnowflakeFile

import snowflake.snowpark as snowpark
from snowflake.snowpark import Session
from snowflake.snowpark.functions import col
#import pandas as pd
import snowflake.snowpark.functions as F
import yaml
import sys
import json
#import modin.pandas as pd
# Import the Snowpark plugin for modin.
#import snowflake.snowpark.modin.plugin

#where_clause = '""type""=''configuration/entityTypes/HCP'''

# intialize __init___:
#session = snowpark.Session
v_json_prev_field_list=[]  # Global variable 
v_table_name='' # global variable
sql_affected=[0]

#set common fields 
v_audit_columns_list = ['BATCH_ID','CREATED_DATE','CREATED_BY']
v_audit_columns_values_list = ["(select batch_id from mdm.load_master where open_status='Open' and process_name='HCP' limit 1) as BATCH_ID",'CURRENT_TIMESTAMP() AS REC_INSERT_TMPS','CURRENT_USER() AS REC_CREATED_BY']

def cust_address(session,config_file,interface_name):
    yield(interface_name)

def get_open_batch_id(session,source='HCP') -> str:
     v_select_str = "select batch_id from mdm.load_master where open_status='Open' and process_name='{}'  order by batch_id desc limit 1".format(source)
     batch_id = session.sql(v_select_str).collect()
     if batch_id: 
        batch_id = batch_id[0][0]  # this could lead to error reqauired error handling 
        return batch_id
     return 'ERROR:Open batch_id not found!'

def open_batch(session,suorce='HCP') -> None:
    v_insert_open_bartch_sql_str = "insert into mdm.load_master(batch_id,process_name,start_time,open_status) \
                                    values((select (case when max(batch_id) is null then 0 else max(batch_id) end) + 1 from  load_master),'{}',current_timestamp(),'Open')".format(suorce)
    #Open the batch 
    sql_affected=session.sql(v_insert_open_bartch_sql_str).collect() 
    batch_id=get_open_batch_id(session)
    #insert to log 
    insert_to_log(session,batch_id=batch_id,rows_affect=sql_affected[0],interface_name='LOAD_MASTER= batch closed successfully!') 

def close_batach(session,source: str) -> None:
    # global sql_affected
    # sql_affected=[0]
    batch_id=get_open_batch_id(session)
    sql_affected = session.sql("update MDM.load_master set OPEN_STATUS='Closed' ,END_TIME={} where PROCESS_NAME='{}'   and batch_id='{}'".format('current_timestamp()',source,batch_id)).collect()
    #insert to log 
    insert_to_log(session,batch_id=batch_id,rows_affect=sql_affected[0],interface_name='LOAD_MASTER') 
    
def unpack_json_mdm(session,source_name):
    batch_id=get_open_batch_id(session)
    fd = session.file.get_stream("@ABBV_SMDW_DEV.MDMV.MY_INT_STAGE1/config/project_config3.yml", decompress=False)
    res =  fd.read() 
    fd.close()
    #with SnowflakeFile.open(sc_url) as f:
    config_read=yaml.safe_load(res)
    column_list = config_read["CANONICAL-MDM"]
    #take only keys start with MDM are considered as table in yml config file
    v_stg_table_list =[key for key ,val in column_list.items() if key[:3] =='MDM']
    
    for stg_table in v_stg_table_list:
        if stg_table not in ['MDM_CUSTOMER_IDENTIFIER','MDM_CUSTOMER_CROSS_WALK']:
            sql_=get_sql(session,source=source_name,interface_name=stg_table)
        elif stg_table == 'MDM_CUSTOMER_IDENTIFIER' :
            #after above steps completed next unpack result insert to stg_mdm_customer_identifier table 
            sql_affected = session.sql("call MDM_COMMON_STG_LOAD_SP()").collect()    
            #insert_to_log(session,batch_id=batch_id,rows_affect=sql_affected[0],business_name=stg_table,interface_name="STG_{}".format(stg_table))  
  
    return v_stg_table_list

def insert_to_log(session,batch_id=None,source='HCP',rows_affect=None,status='ok',business_name=None,interface_name=None,query_txt='None') -> None:
    if status=='ok':
        v_insert_comment_str = "process completed succesfully: {}".format(rows_affect)
    else:
         v_insert_comment_str = "process failed:"
         
    v_process_tracking_sql_str_1 = "insert into mdm.mdm_etl_process_tracking(batch_id,PROCESS_NAME,BUSINES_NAME,STG_TB_NAME,step_description,rec_ins_tmsp,query_txt,status)"
    v_process_tracking_sql_str_2 = " values('{}','{}','{}','{}','{}',{},'{}','{}')".format(batch_id,source,business_name,interface_name,v_insert_comment_str,'current_timestamp()',query_txt.replace("'","''"),status)
    
    sql_affected=session.sql(v_process_tracking_sql_str_1 + v_process_tracking_sql_str_2).collect()
    
def  setup_dependencies(session,source):
    if source == 'HCP':
        #open batch : 
       # open_batch(session)
        #create cross walk common dependent stg table
        v_insert_sql_str1 = 'INSERT INTO MDM.STG_MDM_CUSTOMER_CROSS_WALK(URI,attributes_uri,data_source_uri,data_source_provider_name,BATCH_ID,CREATED_DATE,CREATED_BY) \
                            SELECT "uri" as URI ,attributes.value::string as attributes_uri,crosswalks.value:type::string as data_source_uri\
                            ,substr(data_source_uri,23) as data_source_provider_name\
                            ,(select batch_id from mdm.load_master where open_status=''\'Open''\' and process_name=''\'HCP''\' limit 1) as BATCH_ID\
                            ,CURRENT_TIMESTAMP() AS REC_INSERT_TMPS\
                            ,CURRENT_USER() AS REC_CREATED_BY \
                            FROM ABBV_SMDW_DEV.MDM.ENTITIES_HCP_VW_STREAM_T P\
                            ,lateral flatten (input => "crosswalks", outer => true) crosswalks\
                            ,lateral flatten (input => crosswalks.value:"attributes",  outer => true) attributes'
    # #insert to dependent crosswak table 
    sql_affected=session.sql(v_insert_sql_str1).collect()
    batch_id=get_open_batch_id(session)
    #insert to log
    insert_to_log(session,batch_id=batch_id,rows_affect=sql_affected[0],interface_name='STG_MDM_CROSS_WALK') 
    return sql_affected
def build_flatten_class(session,Objects) -> str:
    str1='--'
    #return "LATERAL FLATTEN(input => ""attributes"":" + Objects[0] + ", outer => true) {}".format(Objects[0])
    # eg: - SFAAddressID: [value,string,SFA_ADDRESSID,Address]
    v_json_field_str=list(Objects.keys())[0]     #  SFAAddressID
    v_json_value_str=list(Objects.values())[0][0]  # value
    v_json_dataType_str=list(Objects.values())[0][1] # string
    v_json_alias_str =list(Objects.values())[0][2] #  SFA_ADDRESSID 
    v_json_path_str =list(Objects.values())[0][3]   #  Address

    #global v_json_prev_field_list

    if v_json_field_str.strip() not in v_json_prev_field_list:  # avoid the duplicate   aliases in latteral flatten inline sql
        # list to keep tracking of flatten inline Query , to avoid the dupicate inline query 
        v_json_prev_field_list.append(v_json_field_str.strip())  

        #if v_table_name != 'NA': #'MDM_CUSTOMER_SALESTEAM':
        print(str1)
        if v_json_path_str.strip() != 'NA':
           str1= "LATERAL FLATTEN(input => {}.value:value ,path => '{}', outer => true) {}".format(v_json_path_str,v_json_field_str.replace(' ',''),v_json_field_str)
        else: 
           str1= 'LATERAL FLATTEN(input => "attributes":' + v_json_field_str + ", outer => true) {}".format(v_json_field_str)
    return str1
def build_filter_class(session,Objects):
    v_json_field_str=list(Objects.keys())[0]
    v_json_value_str=list(Objects.values())[0][0]
    v_json_dataType_str=list(Objects.values())[0][1]
    v_json_alias_str =list(Objects.values())[0][3]

    return "NVL({}.value:ov::string,'true')='true'".format(v_json_field_str)

#def save_data(df_save,to_table_name) --> str:
#   df_save.write.mode("append").save_as_table(to_table_name,column_order='name') 

def get_sql(session,source=None,interface_name=None):
    global v_table_name 
    v_table_name = interface_name
    batch_id = session.sql("select batch_id from mdm.load_master where open_status='Open' and process_name='HCP' limit 1").collect()
    unpack_sql=''
    global v_json_prev_field_list
    v_json_prev_field_list=[]
    if batch_id:
        global sql_affected
        sql_affected=[0]
        batch_id=batch_id[0][0]
        fd = session.file.get_stream("@ABBV_SMDW_DEV.MDMV.MY_INT_STAGE1/config/project_config3.yml", decompress=False)
        res =  fd.read() 
        fd.close()
        #with SnowflakeFile.open(sc_url) as f:
        config_read=yaml.safe_load(res)
        column_list = config_read["CANONICAL-MDM"][interface_name.upper()]
        database_name = config_read["CANONICAL-MDM"]["DATABASE_NAME"]
        schema_name = config_read["CANONICAL-MDM"]["SCHEMA_NAME"]
        where_clause = " WHERE type='configuration/entityTypes/HCP'"

        #prepare default column list 

        v_default_columns_select_list = [my_dic for my_dic in column_list if list(my_dic.keys())[0] == 'Default']
        v_default_columns_select_list_1=(v_default_columns_select_list[0])['Default']
        v_default_columns_select_list_2 = [ "{} as {}".format(x[0],x[1]) for x in v_default_columns_select_list_1]
        # v_default_columns_select_list_3 = ','.join(v_default_columns_select_list)

        #default columns for insert sql (col1,col2...)
        v_dafault_to_save_columns_list_4 = [x[1] for x in v_default_columns_select_list_1]

        #prepare insert sql columns parameters using the both main select columns list + default columns + audit columms (col1,col2....)

        v_to_save_columns_list = [list(my_dic.values())[0][2] for my_dic in column_list  \
        if (list(my_dic.values())[0])[0] != 'NA' and list(my_dic.keys())[0] != 'Default'] +  v_dafault_to_save_columns_list_4 + v_audit_columns_list

        v_to_save_columns_str = ','.join(v_to_save_columns_list)
        v_to_save_columns_str ="INSERT INTO STG_{}({})".format(interface_name,v_to_save_columns_str)

        #select section of unpack sql, all columns in select unpack sql
        v_select_colummns_unpack_1_str=[list(my_dic.keys())[0] + ".value:" + (list(my_dic.values())[0])[0]\
                + "::" + (list(my_dic.values())[0])[1] + " as {}".format(list(my_dic.values())[0][2]) \
                for my_dic in column_list if (list(my_dic.values())[0])[0] != 'NA' and list(my_dic.keys())[0] != 'Default' ] \
                + v_default_columns_select_list_2 + v_audit_columns_values_list
        
        v_select_colummns_unpack_1_str = "\n,".join(v_select_colummns_unpack_1_str)
        #lateral flatten section of unpack sql
        v_flatten_unpack_2_str = [build_flatten_class(session,my_dic) for my_dic in column_list if list(my_dic.keys())[0] not in v_json_prev_field_list and list(my_dic.keys())[0] != 'Default'] 
        #remove NONE values : 
        v_flatten_unpack_2_str=[i for i in v_flatten_unpack_2_str if i is not None] # remove none values from the lis
        v_flatten_unpack_2_str="\n,".join(v_flatten_unpack_2_str)
        v_flatten_unpack_2_str.replace(',--','')         
        #fitler section of unpack sql
        v_filter_unpack_3_str=''
        if interface_name == 'MDM_CUSTOMER_MASTER':  # currently filter is used only for customer_master fo other tables add into this list 
            v_filter_unpack_3_str = [build_filter_class(session,my_dic) for my_dic in column_list if (list(my_dic.values())[0])[0] != 'NA' and list(my_dic.keys())[0] != 'Default']
            v_filter_unpack_3_str = "\n AND ".join(v_filter_unpack_3_str)
            v_filter_unpack_3_str = "WHERE " + v_filter_unpack_3_str
        #build from class of unpack sql
        #v_from_clause_str = "FROM {}.{}.{}_VW_STREAMS P".format(database_name,schema_name,interface_name)
        v_from_clause_str = "FROM {}.{}.{}_HCP_VW_STREAM_T P".format(database_name,'MDM','ENTITIES')

        #build full unpack sql
        unpack_sql = "{} \n SELECT DISTINCT \n {} \n {} ,\n {}  \n {}".format(v_to_save_columns_str,v_select_colummns_unpack_1_str, v_from_clause_str, v_flatten_unpack_2_str,v_filter_unpack_3_str)
        #create stg tables 
    
        sql_affected = session.sql(unpack_sql).collect()
        

        ## capture the process log succesfully completed status :
        insert_to_log(session,batch_id=batch_id,rows_affect=sql_affected[0],business_name=interface_name,interface_name="STG_{}".format(interface_name),query_txt=unpack_sql) 
        
    else:
        ### capture the process log failed status :
        
        insert_to_log(session,batch_id=batch_id,rows_affect=sql_affected[0],business_name=interface_name,interface_name="STG_{}".format(interface_name),status='Failed') 
        unpack_sql = "ERROR: not batch open found for source: HCP"
    return  unpack_sql #sql_affected
    #return v_process_tracking_sql_str_1 + v_process_tracking_sql_str_2
#if __name__ == "__main__":
#    #print(get_sql('MDM_CUSTOMER_MASTER'))
#     print(get_sql('MDM_CUSTOMER_MASTER'))
